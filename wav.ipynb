{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP81zyqY6og3A8eq2JVOY7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y22ecprojectb3-max/speech/blob/main/wav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9VnSl5qSOv",
        "outputId": "8f2ed330-8a92-4e45-8afa-f7ffa560b013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the main zip file\n",
        "main_zip_path = '/content/drive/MyDrive/DS_10283_1942.zip'\n",
        "\n",
        "# Final dataset directory\n",
        "dataset_dir = '/content/dataset'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# Open the main zip file\n",
        "with zipfile.ZipFile(main_zip_path, 'r') as main_zip_ref:\n",
        "    # Loop through all files inside the main zip file\n",
        "    for file_info in main_zip_ref.infolist():\n",
        "        file_name = file_info.filename\n",
        "\n",
        "        # Only process .zip files within the main zip\n",
        "        if file_name.endswith(\".zip\"):\n",
        "            # Create a target directory for each inner zip file\n",
        "            target_dir = os.path.join(dataset_dir, os.path.splitext(file_name)[0])\n",
        "            os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "            # Extract the inner zip file\n",
        "            main_zip_ref.extract(file_info, dataset_dir)\n",
        "\n",
        "            # Extract the contents of the inner zip file into its target directory\n",
        "            inner_zip_path = os.path.join(dataset_dir, file_name)\n",
        "            with zipfile.ZipFile(inner_zip_path, 'r') as inner_zip_ref:\n",
        "                inner_zip_ref.extractall(target_dir)\n",
        "                print(f\"âœ… Extracted {file_name} â†’ {target_dir}\")\n",
        "\n",
        "            # Remove the extracted inner zip file after extraction\n",
        "            os.remove(inner_zip_path)"
      ],
      "metadata": {
        "id": "0L-_1LSwq8st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first 10 files in the noisy training set\n",
        "!ls /content/dataset/noisy_trainset_wav | head -n 10\n"
      ],
      "metadata": {
        "id": "T6n55oFmrtaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check extracted folders\n",
        "for root, dirs, files in os.walk('/content/dataset'):\n",
        "    print(f\"\\nFolder: {root}\")\n",
        "    for f in files[:10]:  # show only first 10 files\n",
        "        print(\"   \", f)"
      ],
      "metadata": {
        "id": "B2trpb8Lt6rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechbrain pydub\n",
        "\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n",
        "from pydub import AudioSegment\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd"
      ],
      "metadata": {
        "id": "zwSQrC5htu0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SpeechBrain's speech enhancement model\n",
        "enhancer = SpectralMaskEnhancement.from_hparams(\n",
        "    source=\"speechbrain/metricgan-plus-voicebank\",\n",
        "    savedir=\"pretrained_models/metricgan-plus-voicebank\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "RxiDZABjuCjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check clean/noisy speech files\n",
        "print(\"Clean trainset samples:\", len(os.listdir(\"/content/dataset/clean_trainset_wav\")))\n",
        "print(\"Noisy trainset samples:\", len(os.listdir(\"/content/dataset/noisy_trainset_wav\")))\n",
        "print(\"Clean testset samples:\", len(os.listdir(\"/content/dataset/clean_testset_wav\")))\n",
        "print(\"Noisy testset samples:\", len(os.listdir(\"/content/dataset/noisy_testset_wav\")))\n",
        "\n",
        "# Show a few transcript files\n",
        "print(\"\\nTranscript samples:\")\n",
        "print(os.listdir(\"/content/dataset/trainset_txt\")[:10])\n"
      ],
      "metadata": {
        "id": "LnJ85la5rzh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "import random\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "# Pick a random noisy and clean file\n",
        "noisy_file = \"/content/dataset/noisy_trainset_wav/p226_001.wav\"\n",
        "clean_file = \"/content/dataset/clean_trainset_wav/p226_001.wav\"\n",
        "\n",
        "# Read audio files\n",
        "rate_noisy, audio_noisy = wavfile.read(noisy_file)\n",
        "rate_clean, audio_clean = wavfile.read(clean_file)\n",
        "\n",
        "print(\"Noisy Speech:\")\n",
        "ipd.display(ipd.Audio(audio_noisy, rate=rate_noisy))\n",
        "\n",
        "print(\"Clean Speech (Ground Truth):\")\n",
        "ipd.display(ipd.Audio(audio_clean, rate=rate_clean))"
      ],
      "metadata": {
        "id": "Ugl7eXzJr7o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "import scipy.io.wavfile as wavfile\n",
        "import os\n",
        "\n",
        "# Example: play noisy and clean speech\n",
        "noisy_file = \"/content/dataset/noisy_trainset_wav/p226_001.wav\"\n",
        "clean_file = \"/content/dataset/clean_trainset_wav/p226_001.wav\"\n",
        "enhanced_file = \"enhanced_speech.wav\" # replace with your output file\n",
        "\n",
        "# Read audio files\n",
        "rate_noisy, audio_noisy = wavfile.read(noisy_file)\n",
        "rate_clean, audio_clean = wavfile.read(clean_file)\n",
        "\n",
        "print(\"ðŸ”Š Noisy Speech:\")\n",
        "ipd.display(ipd.Audio(audio_noisy, rate=rate_noisy))\n",
        "\n",
        "print(\"ðŸ”Š Clean Speech (Reference):\")\n",
        "ipd.display(ipd.Audio(audio_clean, rate=rate_clean))\n",
        "\n",
        "# Check if enhanced file exists before trying to display it\n",
        "if os.path.exists(enhanced_file):\n",
        "    rate_enhanced, audio_enhanced = wavfile.read(enhanced_file)\n",
        "    print(\"ðŸ”Š Enhanced Speech (after model):\")\n",
        "    ipd.display(ipd.Audio(audio_enhanced, rate=rate_enhanced))\n",
        "else:\n",
        "    print(f\"Enhanced speech file not found at {enhanced_file}. Please run your model to generate it.\")"
      ],
      "metadata": {
        "id": "jk4d-ntcsf8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "import scipy.io.wavfile as wavfile\n",
        "import os\n",
        "\n",
        "# Example: play noisy and clean speech\n",
        "noisy_file = \"/content/dataset/noisy_trainset_wav/p226_001.wav\"\n",
        "clean_file = \"/content/dataset/clean_trainset_wav/p226_001.wav\"\n",
        "enhanced_file = \"enhanced_speech.wav\" # replace with your output file\n",
        "\n",
        "# Read audio files\n",
        "rate_noisy, audio_noisy = wavfile.read(noisy_file)\n",
        "rate_clean, audio_clean = wavfile.read(clean_file)\n",
        "\n",
        "print(\"ðŸ”Š Noisy Speech:\")\n",
        "ipd.display(ipd.Audio(audio_noisy, rate=rate_noisy))\n",
        "\n",
        "print(\"ðŸ”Š Clean Speech (Reference):\")\n",
        "ipd.display(ipd.Audio(audio_clean, rate=rate_clean))\n",
        "\n",
        "# Check if enhanced file exists before trying to display it\n",
        "if os.path.exists(enhanced_file):\n",
        "    rate_enhanced, audio_enhanced = wavfile.read(enhanced_file)\n",
        "    print(\"ðŸ”Š Enhanced Speech (after model):\")\n",
        "    ipd.display(ipd.Audio(audio_enhanced, rate=rate_enhanced))\n",
        "else:\n",
        "    print(f\"Enhanced speech file not found at {enhanced_file}. Please run your model to generate it.\")"
      ],
      "metadata": {
        "id": "ek9BC_ystPh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/dataset/noisy_trainset_wav | head -n 10\n"
      ],
      "metadata": {
        "id": "G8IE6U3vuK8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechbrain\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n"
      ],
      "metadata": {
        "id": "oI2048HduK11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enhancer = SpectralMaskEnhancement.from_hparams(\n",
        "    source=\"speechbrain/metricgan-plus-voicebank\",\n",
        "    savedir=\"pretrained_models/metricgan-plus-voicebank\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "DgRCTxf6uxiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_file = \"/content/dataset/noisy_trainset_wav/p226_010.wav\"  # change to a real file\n",
        "waveform, fs = torchaudio.load(noisy_file)\n",
        "\n",
        "print(\"Noisy Speech:\")\n",
        "import IPython.display as ipd\n",
        "ipd.display(ipd.Audio(noisy_file))\n"
      ],
      "metadata": {
        "id": "ApRFLavLu2ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c4beeb1"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "\n",
        "enhanced = enhancer.enhance_batch(waveform, lengths=torch.tensor([1.0]))\n",
        "\n",
        "# Save enhanced speech\n",
        "torchaudio.save(\"enhanced_speech.wav\", enhanced.cpu(), fs)\n",
        "\n",
        "print(\"âœ… Enhanced speech saved as enhanced_speech.wav\")\n",
        "ipd.display(ipd.Audio(\"enhanced_speech.wav\"))"
      ],
      "metadata": {
        "id": "0LJ1OuPrvXQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ade2516d"
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "\n",
        "enhanced = enhancer.enhance_batch(waveform, lengths=torch.tensor([1.0]))\n",
        "\n",
        "# Save enhanced speech\n",
        "torchaudio.save(\"enhanced_speech.wav\", enhanced.cpu(), fs)\n",
        "\n",
        "print(\"âœ… Enhanced speech saved as enhanced_speech.wav\")\n",
        "ipd.display(ipd.Audio(\"enhanced_speech.wav\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "enhanced_waveform, fs = torchaudio.load(\"enhanced_speech.wav\")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(waveform[0].numpy())\n",
        "plt.title(\"Noisy Speech\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(enhanced_waveform[0].numpy())\n",
        "plt.title(\"Enhanced Speech\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ixeVldbTvqCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "# Example: play noisy and clean speech\n",
        "noisy_file = \"/content/dataset/noisy_trainset_wav/p226_010.wav\"\n",
        "clean_file = \"/content/dataset/clean_trainset_wav/p226_010.wav\"\n",
        "\n",
        "print(\"ðŸ”Š Noisy Speech:\")\n",
        "ipd.display(ipd.Audio(noisy_file))\n",
        "\n",
        "print(\"ðŸ”Š Clean Speech (Reference):\")\n",
        "ipd.display(ipd.Audio(clean_file))\n",
        "\n",
        "print(\"ðŸ”Š Enhanced Speech (after model):\")\n",
        "ipd.display(ipd.Audio(\"enhanced_speech.wav\"))  # replace with your output file\n"
      ],
      "metadata": {
        "id": "NfMgbLrJwJ8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/dataset/noisy_trainset_wav | head -n 10\n"
      ],
      "metadata": {
        "id": "5NfRcPuswXoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "waveform, sr = torchaudio.load(noisy_file)\n",
        "enhanced_waveform, sr = torchaudio.load(\"enhanced_speech.wav\")  # your output\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(waveform[0].numpy())\n",
        "plt.title(\"Noisy Speech\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(enhanced_waveform[0].numpy())\n",
        "plt.title(\"Enhanced Speech\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6vKxQaKGwcSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "# Example: play noisy and clean speech\n",
        "noisy_file = \"/content/dataset/noisy_trainset_wav/p226_009.wav\"\n",
        "clean_file = \"/content/dataset/clean_trainset_wav/p226_009.wav\"\n",
        "\n",
        "print(\"ðŸ”Š Noisy Speech:\")\n",
        "ipd.display(ipd.Audio(noisy_file))\n",
        "\n",
        "print(\"ðŸ”Š Clean Speech (Reference):\")\n",
        "ipd.display(ipd.Audio(clean_file))\n",
        "\n",
        "print(\"ðŸ”Š Enhanced Speech (after model):\")\n",
        "ipd.display(ipd.Audio(\"enhanced_speech.wav\"))  # replace with your output file\n"
      ],
      "metadata": {
        "id": "72U07MPgwllw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/dataset/noisy_trainset_wav | head -n 10\n"
      ],
      "metadata": {
        "id": "-SrjKcwOw5qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "waveform, sr = torchaudio.load(noisy_file)\n",
        "enhanced_waveform, sr = torchaudio.load(\"enhanced_speech.wav\")  # your output\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(waveform[0].numpy())\n",
        "plt.title(\"Noisy Speech\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(enhanced_waveform[0].numpy())\n",
        "plt.title(\"Enhanced Speech\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vG8Vp0olxKwj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}